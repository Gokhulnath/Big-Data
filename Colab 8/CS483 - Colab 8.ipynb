{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPt5q27L5557"
   },
   "source": [
    "# CS483 - Colab 8\n",
    "## Bloom Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0-YhEpP_Ds-"
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zsj5WYpR9QId"
   },
   "source": [
    "In this Colab, we need to install a [bloom_filter](https://github.com/hiway/python-bloom-filter), a Python library which offers an implementation of Bloom filters.  Run the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12705,
     "status": "ok",
     "timestamp": 1684983019552,
     "user": {
      "displayName": "Nirali Sharad Parekh",
      "userId": "02249563440626634370"
     },
     "user_tz": 420
    },
    "id": "k-qHai2252mI",
    "outputId": "cfa54bd4-8ff0-4aee-f3b1-295be00c223e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting bloom_filter\n",
      "  Downloading bloom_filter-1.3.3-py3-none-any.whl (8.1 kB)\n",
      "Installing collected packages: bloom_filter\n",
      "Successfully installed bloom_filter-1.3.3\n"
     ]
    }
   ],
   "source": [
    "!pip install bloom_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAYRX2PMm0L6"
   },
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XO_IcxgquzhI"
   },
   "source": [
    "From the NLTK (Natural Language ToolKit) library, we import a large list of English dictionary words, commonly used by the very first spell-checking programs in Unix-like operating systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3342,
     "status": "ok",
     "timestamp": 1684983022887,
     "user": {
      "displayName": "Nirali Sharad Parekh",
      "userId": "02249563440626634370"
     },
     "user_tz": 420
    },
    "id": "-Xz3f79crEEb",
    "outputId": "4f71fb13-d442-460a-8df5-40d569d59ec2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary length: 236736\n",
      "['A', 'a', 'aa', 'aal', 'aalii', 'aam', 'Aani', 'aardvark', 'aardwolf', 'Aaron', 'Aaronic', 'Aaronical', 'Aaronite', 'Aaronitic', 'Aaru']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('words')\n",
    "\n",
    "from nltk.corpus import words\n",
    "word_list = words.words()\n",
    "print(f'Dictionary length: {len(word_list)}')\n",
    "print(word_list[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csbQXPUFUMob"
   },
   "source": [
    "Then we load another dataset from the NLTK Corpora collection: ```movie_reviews```.\n",
    "\n",
    "The movie reviews are categorized between *positive* and *negative*, so we construct a list of words (usually called **bag of words**) for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4141,
     "status": "ok",
     "timestamp": 1684983347782,
     "user": {
      "displayName": "Nirali Sharad Parekh",
      "userId": "02249563440626634370"
     },
     "user_tz": 420
    },
    "id": "HwgRhMT1UNUt",
    "outputId": "6248f794-18ef-4e2a-a82c-7c7c4555d8b6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "nltk.download('movie_reviews')\n",
    "\n",
    "neg_reviews = []\n",
    "pos_reviews = []\n",
    "\n",
    "for fileid in movie_reviews.fileids('neg'):\n",
    "  neg_reviews.extend(movie_reviews.words(fileid))\n",
    "for fileid in movie_reviews.fileids('pos'):\n",
    "  pos_reviews.extend(movie_reviews.words(fileid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CRaF2A_j_nC7"
   },
   "source": [
    "### Your task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrHJptH3Tb-3"
   },
   "source": [
    "In this Colab, you will develop a very simplistic spell-checker.  By no means you should think of using it for a real-world use case, but it is an interesting exercise to highlight the strenghts and weaknesses of Bloom Filters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 2344,
     "status": "ok",
     "timestamp": 1684983350118,
     "user": {
      "displayName": "Nirali Sharad Parekh",
      "userId": "02249563440626634370"
     },
     "user_tz": 420
    },
    "id": "bK3WyXaPsa5q"
   },
   "outputs": [],
   "source": [
    "from bloom_filter import BloomFilter\n",
    "\n",
    "word_filter = BloomFilter(max_elements=236736)\n",
    "\n",
    "for word in word_list:\n",
    "  word_filter.add(word)\n",
    "\n",
    "word_set = set(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ddqg0odiaSRg"
   },
   "source": [
    "If you executed the cell above, you now have 3 different variables in your scope:\n",
    "\n",
    "1.   ```word_list```, a Python list containing the English dictionary (in case insensitive order)\n",
    "2.   ```word_filter```, a Bloom filter where we have already added all the words in the English dictionary\n",
    "3.   ```word_set```, a [Python set](https://docs.python.org/3.6/library/stdtypes.html#set-types-set-frozenset) built from the same list of words in the English dictionary\n",
    "\n",
    "Let's inspect the size of each datastructure using the [getsizeof()](https://docs.python.org/3/library/sys.html#sys.getsizeof) method!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1684983350118,
     "user": {
      "displayName": "Nirali Sharad Parekh",
      "userId": "02249563440626634370"
     },
     "user_tz": 420
    },
    "id": "FVLxu20maRLf",
    "outputId": "bdf102a0-18e2-4157-82e2-eb4ffdb890f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of word_list (in bytes): 2055512\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' For sub-parts of the question (if any), creating different cells of code would be recommended.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sys import getsizeof\n",
    "\n",
    "print(f'Size of word_list (in bytes): {getsizeof(word_list)}')\n",
    "\n",
    "# YOUR CODE HERE\n",
    "''' 1-2 lines of code in total expected but can differ based on your style. '''\n",
    "''' For sub-parts of the question (if any), creating different cells of code would be recommended.'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbQzd4czlT3h"
   },
   "source": [
    "You should have noticed how efficient is the Bloom filter in terms of memory footprint!\n",
    "\n",
    "Now let's find out how fast is the main operation for which we construct Bloom filters: *membership testing*. To do so, we will use the ```%timeit``` IPython magic command, which times the repeated execution of a single Python statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 1561,
     "status": "ok",
     "timestamp": 1684983351657,
     "user": {
      "displayName": "Nirali Sharad Parekh",
      "userId": "02249563440626634370"
     },
     "user_tz": 420
    },
    "id": "xq7I6kJfwXy5",
    "outputId": "d6171943-0036-452d-fa04-826407065e5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378 µs ± 6.13 µs per loop (mean ± std. dev. of 3 runs, 1000 loops each)\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' 2 lines of code in total expected but can differ based on your style. '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%timeit -r 3 \"California\" in word_list\n",
    "\n",
    "# YOUR CODE HERE\n",
    "''' 2 lines of code in total expected but can differ based on your style. '''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qq2LVgEVnI_R"
   },
   "source": [
    "Notice the performance gap between linear search on a list, multiple hash computations in a Bloom filter, and a single hash computation in a native Python ```Set()```.\n",
    "\n",
    "We now have all the building blocks required to build our spell-checker, and we understand the performance tradeoffs of each datastructure we chose. Write a function that takes as arguments (1) a list of words, and (2) any of the 3 dictionary datastructures we constructed. The function must return the number of words which **do not appear** in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1684983351657,
     "user": {
      "displayName": "Nirali Sharad Parekh",
      "userId": "02249563440626634370"
     },
     "user_tz": 420
    },
    "id": "lTT-6rQcnibH",
    "outputId": "5170b428-a647-42fa-f038-be7147f5ee3a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' 8-10 lines of code for the tests and errors identification (ref gradescope) '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "''' 5-7 lines of code in total expected for the function but can differ based on your style. '''\n",
    "\n",
    "''' 8-10 lines of code for the tests and errors identification (ref gradescope) '''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIrXJyVNP2AI"
   },
   "source": [
    "Once you have working code for each cell above, **head over to Gradescope, read carefully the questions, and submit your solution for this Colab**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oPxLGYO31W4W"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1NI01jwKnxSITvK-0RZYJr8THMOFgNBcj",
     "timestamp": 1684982683280
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
