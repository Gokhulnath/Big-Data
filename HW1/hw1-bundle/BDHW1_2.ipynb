{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g85JmutYPoSE",
        "outputId": "274d5b90-70ef-49a0-be98-5ec5faa0dc02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=64e021db8a3ebdf468952dc03b565db316220ae6f29f578306b0f64929d7f687\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.2\n",
            "The following additional packages will be installed:\n",
            "  libxtst6 openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra fonts-nanum fonts-ipafont-gothic\n",
            "  fonts-ipafont-mincho fonts-wqy-microhei fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  libxtst6 openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 3 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 39.6 MB of archives.\n",
            "After this operation, 144 MB of additional disk space will be used.\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "(Reading database ... 123599 files and directories currently installed.)\n",
            "Preparing to unpack .../libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u422-b05-1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u422-b05-1~22.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u422-b05-1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u422-b05-1~22.04) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u422-b05-1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u422-b05-1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXe-zHZQPqSs",
        "outputId": "cd66cacf-506d-4005-fd04-3a707ba4a595"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext\n",
        "import pandas as pd\n",
        "import itertools\n",
        "\n",
        "# create the Spark Session\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "# create the Spark Context\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "3RXeazruPr1o"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = sc.textFile(\"/content/browsing.txt\")\n",
        "session = data.map(lambda x: x.split())\n",
        "support_threshold = 120\n",
        "top_n = 5"
      ],
      "metadata": {
        "id": "9_6tsNwCf5mj"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_frequent_items(session, support_threshold):\n",
        "    freq_items_support = (session\n",
        "        .flatMap(lambda x: [(item, 1) for item in x])\n",
        "        .reduceByKey(lambda count1, count2: count1 + count2)\n",
        "        .filter(lambda item: item[1] >= support_threshold)\n",
        "        .sortByKey())\n",
        "\n",
        "    return {item[0]: item[1] for item in freq_items_support.collect()}\n",
        "\n",
        "def build_pairs(basket, freq_items):\n",
        "    pairs = []\n",
        "    if len(basket) < 2:\n",
        "        return pairs\n",
        "\n",
        "    for i, item1 in enumerate(basket[:-1]):\n",
        "        for item2 in basket[i + 1:]:\n",
        "            if all(item in freq_items for item in (item1, item2)):\n",
        "                key = (item1, item2) if item1 < item2 else (item2, item1)\n",
        "                val = [freq_items[item] for item in key] + [1]\n",
        "                pairs.append((key, tuple(val)))\n",
        "    return pairs\n",
        "\n",
        "def compute_pair_support(session, freq_items):\n",
        "    return (session\n",
        "        .flatMap(lambda basket: build_pairs(basket, freq_items))\n",
        "        .reduceByKey(lambda x, y: (x[0], x[1], x[2] + y[2])))\n",
        "\n",
        "def compute_pair_confidence(pair_support):\n",
        "    def pair_conf(pair):\n",
        "        (i1, i2), (s1, s2, s12) = pair\n",
        "        return [((i1, i2), s12 / s1),\n",
        "                ((i2, i1), s12 / s2)]\n",
        "\n",
        "    return pair_support.flatMap(pair_conf)\n",
        "\n",
        "freq_items = compute_frequent_items(session, support_threshold)\n",
        "print(\"Number of frequent item sets:\", len(freq_items))\n",
        "\n",
        "pair_support = compute_pair_support(session, freq_items)\n",
        "conf_pair = compute_pair_confidence(pair_support)\n",
        "sorted_pairs = sorted(conf_pair.collect(), key=lambda r: (-r[1], r[0][0]))\n",
        "for rel in sorted_pairs[:top_n]:\n",
        "  (a, b), conf = rel\n",
        "  line = f\"{a} -> {b} = {conf:.10f}\"\n",
        "  print(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bwfh1f78VjjM",
        "outputId": "e8223049-24d6-4883-b9b2-49c87546c21e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of frequent item sets: 553\n",
            "DAI93865 -> FRO40251 = 1.0000000000\n",
            "GRO85051 -> FRO40251 = 0.9991762768\n",
            "DAI88079 -> FRO40251 = 0.9867256637\n",
            "FRO92469 -> FRO40251 = 0.9835100118\n",
            "DAI43868 -> SNA82528 = 0.9729729730\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_frequent_pair_support(pair_support, support_threshold):\n",
        "    return pair_support.filter(lambda x: x[1][2] >= support_threshold)\n",
        "\n",
        "def build_triples(basket, freq_items, freq_pairs):\n",
        "    triples = []\n",
        "    if len(basket) < 3:\n",
        "        return triples\n",
        "\n",
        "    for i, item1 in enumerate(basket[:-2]):\n",
        "        for j in range(i + 1, len(basket) - 1):\n",
        "            item2 = basket[j]\n",
        "            for item3 in basket[j + 1:]:\n",
        "                triple = sorted([item1, item2, item3])\n",
        "\n",
        "                if all(item in freq_items for item in triple):\n",
        "                    pairs = [tuple(triple[:idx] + triple[idx + 1:]) for idx in range(len(triple))]\n",
        "\n",
        "                    if all(pair in freq_pairs for pair in pairs):\n",
        "                        val = [freq_pairs[pair] for pair in pairs] + [1]\n",
        "                        triples.append((tuple(triple), tuple(val)))\n",
        "    return triples\n",
        "\n",
        "def compute_triple_confidence(rdd):\n",
        "    (i1, i2, i3), (s12, s13, s23, s123) = rdd\n",
        "    return [((i1, i2, i3), s123 / s12),\n",
        "            ((i1, i3, i2), s123 / s13),\n",
        "            ((i2, i3, i1), s123 / s23)]\n",
        "\n",
        "freq_pair_support = compute_frequent_pair_support(pair_support, s)\n",
        "freq_pairs = {x[0]: x[1][2] for x in freq_pair_support.collect()}\n",
        "\n",
        "conf_triple = (session\n",
        "    .flatMap(lambda basket: build_triples(basket, freq_items, freq_pairs))\n",
        "    .reduceByKey(lambda x, y: (x[0], x[1], x[2], x[3] + y[3]))\n",
        "    .flatMap(compute_triple_confidence))\n",
        "\n",
        "sorted_triples = sorted(conf_triple.collect(), key=lambda r: (-r[1], r[0][0], r[0][1]))\n",
        "for rel in sorted_triples[:top_n]:\n",
        "            (a, b, c), conf = rel\n",
        "            line = f\"{a}, {b} -> {c} = {conf:.10f}\"\n",
        "            print(line)\n",
        "sc.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3twXLLublVN",
        "outputId": "f4ffde6e-3275-48e3-a6bf-8300ab48c07a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DAI23334, ELE92920 -> DAI62779 = 1.0000000000\n",
            "DAI55911, GRO85051 -> FRO40251 = 1.0000000000\n",
            "DAI75645, GRO85051 -> FRO40251 = 1.0000000000\n",
            "ELE17451, GRO85051 -> FRO40251 = 1.0000000000\n",
            "ELE20847, FRO92469 -> FRO40251 = 1.0000000000\n"
          ]
        }
      ]
    }
  ]
}